#!/usr/bin/env python3
"""
ç¯å¢ƒä¾èµ–æ£€æŸ¥è„šæœ¬
ç”¨äºéªŒè¯æ¨ç†ç¯å¢ƒæ˜¯å¦æ­£ç¡®é…ç½®
"""

def check_dependencies():
    """æ£€æŸ¥ä¾èµ–åŒ…æ˜¯å¦å®‰è£…"""
    print("=== æ£€æŸ¥ä¾èµ–ç¯å¢ƒ ===")
    
    missing = []
    
    # 1. numpyæ£€æŸ¥ - éªŒè¯ç‰ˆæœ¬å…¼å®¹æ€§
    try:
        import numpy as np
        version = np.__version__
        print(f"âœ… numpy ({version}) - æ•°å€¼è®¡ç®—")
        if tuple(map(int, version.split('.')[:2])) < (1, 20):
            print(f"    âš ï¸  å»ºè®®å‡çº§åˆ°1.20+ç‰ˆæœ¬ï¼Œå½“å‰{version}å¯èƒ½å­˜åœ¨å…¼å®¹é—®é¢˜")
    except ImportError:
        print(f"âŒ numpy - æ•°å€¼è®¡ç®— (æœªå®‰è£…)")
        missing.append("numpy")
    except Exception as e:
        print(f"âš ï¸  numpy - æ•°å€¼è®¡ç®— (ç‰ˆæœ¬æ£€æŸ¥å¤±è´¥: {e})")
    
    # 2. PIL(Pillow)æ£€æŸ¥ - éªŒè¯å›¾åƒå¤„ç†åŠŸèƒ½
    try:
        from PIL import Image
        import PIL
        version = PIL.__version__
        print(f"âœ… PIL/Pillow ({version}) - å›¾åƒå¤„ç†")
        # æµ‹è¯•åŸºæœ¬å›¾åƒåŠŸèƒ½
        test_img = Image.new('RGB', (10, 10), color='red')
        test_img.resize((5, 5))
    except ImportError:
        print(f"âŒ PIL - å›¾åƒå¤„ç†(Pillow) (æœªå®‰è£…)")
        missing.append("PIL")
    except Exception as e:
        print(f"âš ï¸  PIL - å›¾åƒå¤„ç†(Pillow) (åŠŸèƒ½æµ‹è¯•å¤±è´¥: {e})")
    
    # 3. tensorflowæ£€æŸ¥ - éªŒè¯TFLiteæ¨¡å—
    try:
        import tensorflow as tf
        version = tf.__version__
        print(f"âœ… tensorflow ({version}) - TensorFlow Lite")
        # éªŒè¯TFLiteæ¨¡å—
        from tensorflow.lite.python.interpreter import Interpreter
        print(f"    âœ… TensorFlow Liteè§£é‡Šå™¨å¯ç”¨")
    except ImportError as e:
        if "tensorflow" in str(e).lower():
            print(f"âŒ tensorflow - TensorFlow Lite (æœªå®‰è£…)")
            missing.append("tensorflow")
        else:
            print(f"âš ï¸  tensorflow - TFLiteè§£é‡Šå™¨æ¨¡å—ç¼ºå¤±: {e}")
    except Exception as e:
        print(f"âš ï¸  tensorflow - TensorFlow Lite (æ¨¡å—éªŒè¯å¤±è´¥: {e})")
    
    # 4. onnxæ£€æŸ¥ - éªŒè¯æ¨¡å‹æ ¼å¼æ”¯æŒ
    try:
        import onnx
        version = onnx.__version__
        print(f"âœ… onnx ({version}) - ONNXæ ¼å¼æ”¯æŒ")
        # éªŒè¯åŸºæœ¬åŠŸèƒ½
        onnx.checker.check_model
    except ImportError:
        print(f"âŒ onnx - ONNXæ ¼å¼æ”¯æŒ (æœªå®‰è£…)")
        missing.append("onnx")
    except Exception as e:
        print(f"âš ï¸  onnx - ONNXæ ¼å¼æ”¯æŒ (åŠŸèƒ½éªŒè¯å¤±è´¥: {e})")
    
    # 5. onnxruntimeæ£€æŸ¥ - éªŒè¯æ¨ç†åç«¯
    try:
        import onnxruntime as ort
        version = ort.__version__
        print(f"âœ… onnxruntime ({version}) - ONNX Runtime")
        # æ£€æŸ¥å¯ç”¨çš„execution providers
        providers = ort.get_available_providers()
        cpu_available = 'CPUExecutionProvider' in providers
        if cpu_available:
            print(f"    âœ… CPUæ¨ç†åç«¯å¯ç”¨")
        else:
            print(f"    âš ï¸  CPUæ¨ç†åç«¯ä¸å¯ç”¨")
    except ImportError:
        print(f"âŒ onnxruntime - ONNX Runtime (æœªå®‰è£…)")
        missing.append("onnxruntime")
    except Exception as e:
        print(f"âš ï¸  onnxruntime - ONNX Runtime (åŠŸèƒ½éªŒè¯å¤±è´¥: {e})")
    
    # 6. tflite2onnxæ£€æŸ¥ - éªŒè¯æ¨¡å‹è½¬æ¢å·¥å…·
    try:
        import tflite2onnx
        print(f"âœ… tflite2onnx - TFLiteè½¬ONNX")
        # éªŒè¯æ ¸å¿ƒè½¬æ¢åŠŸèƒ½
        hasattr(tflite2onnx, 'convert')
    except ImportError:
        print(f"âŒ tflite2onnx - TFLiteè½¬ONNX (æœªå®‰è£…)")
        missing.append("tflite2onnx")
    except Exception as e:
        print(f"âš ï¸  tflite2onnx - TFLiteè½¬ONNX (åŠŸèƒ½éªŒè¯å¤±è´¥: {e})")
    
    # 7. TensorRTå®Œæ•´å·¥å…·é“¾æ£€æŸ¥ - éªŒè¯GPUæ¨ç†åç«¯
    print(f"\n=== TensorRTå·¥å…·é“¾æ£€æŸ¥ ===")
    import subprocess
    import os
    
    # 1) æ£€æŸ¥CUDAç¯å¢ƒ - TensorRTçš„åŸºç¡€ä¾èµ–
    print("ğŸ” æ£€æŸ¥CUDAç¯å¢ƒ:")
    tensorrt_issues = []
    try:
        import pycuda
        import pycuda.driver as cuda
        cuda.init()
        
        # åˆ›å»ºCUDAä¸Šä¸‹æ–‡
        device = cuda.Device(0)
        context = device.make_context()
        
        try:
            # GPUä¿¡æ¯
            gpu_name = device.name()
            free, total = cuda.mem_get_info()
            print(f"   âœ… GPU: {gpu_name}")
            print(f"       GPUå†…å­˜: {free//1024//1024}MB / {total//1024//1024}MB")
        finally:
            # æ¸…ç†ä¸Šä¸‹æ–‡
            context.pop()
        
        # CUDAç‰ˆæœ¬
        cuda_runtime_version = cuda.get_version()
        driver_version = cuda.get_driver_version()
        major = driver_version // 1000
        minor = (driver_version % 1000) // 10
        print(f"   âœ… CUDA Runtime: {cuda_runtime_version[0]}.{cuda_runtime_version[1]}")
        print(f"   âœ… CUDA Driver: {major}.{minor}")
        
        # å…¼å®¹æ€§æ£€æŸ¥
        if cuda_runtime_version[0] >= 12:
            print(f"       âœ… CUDAç‰ˆæœ¬å…¼å®¹ (æ”¯æŒTensorRT 8.6)")
        else:
            print(f"       âš ï¸  CUDAç‰ˆæœ¬å¯èƒ½è¿‡ä½ï¼Œå»ºè®®å‡çº§åˆ°12.x")
            tensorrt_issues.append("CUDAç‰ˆæœ¬è¿‡ä½")
            
    except ImportError:
        print(f"   âŒ pycuda - CUDA Pythonç»‘å®š (æœªå®‰è£…)")
        missing.append("pycuda")
        tensorrt_issues.append("pycudaæœªå®‰è£…")
    except Exception as e:
        print(f"   âš ï¸  CUDAç¯å¢ƒæ£€æŸ¥å¤±è´¥: {e}")
        tensorrt_issues.append("CUDAç¯å¢ƒå¼‚å¸¸")
    
    # 2) æ£€æŸ¥TensorRTç³»ç»Ÿåº“è·¯å¾„ - è¿è¡Œæ—¶åº“ä¾èµ–
    print("ğŸ” æ£€æŸ¥TensorRTç³»ç»Ÿåº“:")
    trt_lib_path = os.environ.get('LD_LIBRARY_PATH', '')
    if 'TensorRT' in trt_lib_path or 'tensorrt' in trt_lib_path:
        print(f"   âœ… TensorRTåº“è·¯å¾„: å·²é…ç½®")
    else:
        print(f"   âš ï¸  TensorRTåº“è·¯å¾„: æœªæ£€æµ‹åˆ°LD_LIBRARY_PATHä¸­çš„TensorRTè·¯å¾„")
        print(f"       å½“å‰è·¯å¾„: {trt_lib_path[:100]}...")
        tensorrt_issues.append("TensorRTåº“è·¯å¾„æœªé…ç½®")
    
    # 3) æ£€æŸ¥TensorRT PythonåŒ… - Python API
    print("ğŸ” æ£€æŸ¥TensorRT PythonåŒ…:")
    try:
        import tensorrt as trt
        version = trt.__version__
        print(f"   âœ… tensorrt ({version}) - TensorRT PythonåŒ…")
        # éªŒè¯åŸºæœ¬åŠŸèƒ½
        logger = trt.Logger(trt.Logger.WARNING)
        builder = trt.Builder(logger)
        if builder:
            print(f"       âœ… TensorRTå¼•æ“æ„å»ºå™¨å¯ç”¨")
    except ImportError as e:
        # æ£€æŸ¥æ˜¯å¦æ˜¯ç³»ç»Ÿåº“ç¼ºå¤±ï¼ˆPythonåŒ…å·²å®‰è£…ä½†æ‰¾ä¸åˆ°.soåº“ï¼‰
        if "libnvinfer" in str(e) or "No module named 'tensorrt'" not in str(e):
            print(f"   âš ï¸  tensorrt - PythonåŒ…å·²å®‰è£…ï¼Œä½†ç¼ºå°‘ç³»ç»Ÿçº§TensorRTåº“")
            print(f"       é”™è¯¯: {e}")
            tensorrt_issues.append("TensorRTç³»ç»Ÿåº“ç¼ºå¤±")
        else:
            print(f"   âŒ tensorrt - TensorRT PythonåŒ… (æœªå®‰è£…)")
            missing.append("tensorrt")
    except Exception as e:
        print(f"   âš ï¸  tensorrt - TensorRTåŠŸèƒ½éªŒè¯å¤±è´¥: {e}")
        tensorrt_issues.append("TensorRTåŠŸèƒ½å¼‚å¸¸")
    
    # 4) æ£€æŸ¥TensorRTå‘½ä»¤è¡Œå·¥å…· - æœ€ä¸Šå±‚å·¥å…·
    print("ğŸ” æ£€æŸ¥TensorRTå·¥å…·:")
    tensorrt_tools = [
        ("trtexec", "TensorRTæ€§èƒ½æµ‹è¯•å’Œè½¬æ¢å·¥å…·")
    ]
    
    for tool, description in tensorrt_tools:
        try:
            result = subprocess.run(['which', tool], capture_output=True, text=True, timeout=5)
            if result.returncode == 0:
                tool_path = result.stdout.strip()
                print(f"   âœ… {tool} - {description}")
                print(f"       è·¯å¾„: {tool_path}")
            else:
                print(f"   âŒ {tool} - {description} (æœªæ‰¾åˆ°)")
                tensorrt_issues.append(f"ç¼ºå°‘{tool}å·¥å…·")
        except Exception as e:
            print(f"   âŒ {tool} - {description} (æ£€æŸ¥å¤±è´¥: {e})")
            tensorrt_issues.append(f"{tool}å·¥å…·æ£€æŸ¥å¤±è´¥")
    
    # 10. NCNNå·¥å…·é“¾æ£€æŸ¥ - éªŒè¯CPUç§»åŠ¨ç«¯æ¨ç†å·¥å…·
    print(f"\n=== NCNNå·¥å…·é“¾æ£€æŸ¥ ===")
    import subprocess
    import os
    
    # 1) æ£€æŸ¥protobufä¾èµ– - NCNNå·¥å…·çš„åŸºç¡€ä¾èµ–
    print("ğŸ” æ£€æŸ¥protobufä¾èµ–:")
    ncnn_issues = []
    
    # æ£€æŸ¥LD_LIBRARY_PATHä¸­æ˜¯å¦å­˜åœ¨libprotobuf.so.17
    ld_lib_path = os.environ.get('LD_LIBRARY_PATH', '')
    protobuf_found = False
    
    if ld_lib_path:
        for path in ld_lib_path.split(':'):
            if path.strip():  # è·³è¿‡ç©ºè·¯å¾„
                protobuf_lib = os.path.join(path.strip(), 'libprotobuf.so.17')
                if os.path.exists(protobuf_lib):
                    print(f"   âœ… protobuf-17: ä¾èµ–åº“å¯ç”¨ (NCNNå·¥å…·éœ€è¦)")
                    print(f"       è·¯å¾„: {protobuf_lib}")
                    protobuf_found = True
                    break
    
    if not protobuf_found:
        # å¤‡ç”¨æ£€æŸ¥ï¼šç³»ç»Ÿldconfigç¼“å­˜
        try:
            result = subprocess.run(['ldconfig', '-p'], capture_output=True, text=True, timeout=10)
            if 'libprotobuf.so.17' in result.stdout:
                print(f"   âœ… protobuf-17: ä¾èµ–åº“å¯ç”¨ (ç³»ç»Ÿç¼“å­˜)")
                protobuf_found = True
        except Exception as e:
            pass
        
        if not protobuf_found:
            print(f"   âš ï¸  protobuf-17: æœªæ‰¾åˆ°libprotobuf.so.17 (NCNNå·¥å…·å¯èƒ½æ— æ³•è¿è¡Œ)")
            ncnn_issues.append("protobuf-17ä¾èµ–ç¼ºå¤±")
    
    # 2) æ£€æŸ¥NCNNåº“è·¯å¾„ - è¿è¡Œæ—¶åº“è·¯å¾„
    print("ğŸ” æ£€æŸ¥NCNNåº“è·¯å¾„:")
    ld_lib_path = os.environ.get('LD_LIBRARY_PATH', '')
    if 'ncnn' in ld_lib_path.lower():
        print(f"   âœ… NCNNåº“è·¯å¾„: å·²é…ç½®")
    else:
        print(f"   âš ï¸  NCNNåº“è·¯å¾„: æœªæ£€æµ‹åˆ°LD_LIBRARY_PATHä¸­çš„NCNNè·¯å¾„")
        print(f"       å½“å‰è·¯å¾„: {ld_lib_path[:100]}...")
        ncnn_issues.append("NCNNåº“è·¯å¾„æœªé…ç½®")
    
    # 3) æ£€æŸ¥NCNNå·¥å…·å¯æ‰§è¡Œæ€§ - æœ€ä¸Šå±‚æ£€æŸ¥
    print("ğŸ” æ£€æŸ¥NCNNå·¥å…·:")
    ncnn_tools = [
        ("onnx2ncnn", "ONNXè½¬NCNNæ¨¡å‹è½¬æ¢å™¨"),
        ("ncnnoptimize", "NCNNæ¨¡å‹ä¼˜åŒ–å™¨"),
        ("ncnn2table", "NCNNé‡åŒ–æ ¡å‡†è¡¨ç”Ÿæˆå™¨"),
        ("ncnn2int8", "NCNN INT8é‡åŒ–è½¬æ¢å™¨")
    ]
    
    for tool, description in ncnn_tools:
        try:
            # æ£€æŸ¥å·¥å…·æ˜¯å¦åœ¨PATHä¸­
            result = subprocess.run(['which', tool], capture_output=True, text=True, timeout=5)
            if result.returncode == 0:
                tool_path = result.stdout.strip()
                print(f"   âœ… {tool} - {description}")
                print(f"       è·¯å¾„: {tool_path}")
            else:
                print(f"   âŒ {tool} - {description} (æœªæ‰¾åˆ°)")
                ncnn_issues.append(f"ç¼ºå°‘{tool}å·¥å…·")
        except Exception as e:
            print(f"   âŒ {tool} - {description} (æ£€æŸ¥å¤±è´¥: {e})")
            ncnn_issues.append(f"{tool}å·¥å…·æ£€æŸ¥å¤±è´¥")
    
    # æ£€æŸ¥ç»“æœæ±‡æ€»
    print(f"\n=== æ£€æŸ¥ç»“æœæ±‡æ€» ===")
    
    # æ˜¾ç¤ºç‰ˆæœ¬ä¿¡æ¯
    print("ğŸ“‹ å·²å®‰è£…ç‰ˆæœ¬:")
    try:
        import numpy as np
        print(f"   â€¢ numpy: {np.__version__}")
    except:
        print(f"   â€¢ numpy: æœªå®‰è£…")
    
    try:
        import PIL
        print(f"   â€¢ PIL/Pillow: {PIL.__version__}")
    except:
        print(f"   â€¢ PIL/Pillow: æœªå®‰è£…")
    
    try:
        import tensorflow as tf
        print(f"   â€¢ TensorFlow: {tf.__version__}")
    except:
        print(f"   â€¢ TensorFlow: æœªå®‰è£…")
    
    try:
        import onnx
        print(f"   â€¢ ONNX: {onnx.__version__}")
    except:
        print(f"   â€¢ ONNX: æœªå®‰è£…")
    
    try:
        import onnxruntime as ort
        print(f"   â€¢ ONNX Runtime: {ort.__version__}")
    except:
        print(f"   â€¢ ONNX Runtime: æœªå®‰è£…")
    
    try:
        import tflite2onnx
        print(f"   â€¢ tflite2onnx: {tflite2onnx.__version__}")
    except:
        print(f"   â€¢ tflite2onnx: æœªå®‰è£…")
    
    try:
        import tensorrt as trt
        print(f"   â€¢ TensorRT: {trt.__version__}")
    except:
        print(f"   â€¢ TensorRT: æœªå®‰è£…")
    
    try:
        import pycuda
        print(f"   â€¢ PyCUDA: {pycuda.VERSION_TEXT}")
    except:
        print(f"   â€¢ PyCUDA: æœªå®‰è£…")
    
    # é—®é¢˜æ±‡æ€»
    print("\nğŸ” é—®é¢˜æ±‡æ€»:")
    
    if missing:
        print(f"   âŒ ç¼ºå°‘Pythonä¾èµ–: {', '.join(missing)}")
    
    if tensorrt_issues:
        print(f"   âš ï¸  TensorRTé—®é¢˜: {', '.join(tensorrt_issues)}")
        print(f"      å½±å“: GPUåŠ é€ŸåŠŸèƒ½å—é™")
    
    if ncnn_issues:
        print(f"   âš ï¸  NCNNé—®é¢˜: {', '.join(ncnn_issues)}")
        print(f"      å½±å“: CPUç§»åŠ¨ç«¯ä¼˜åŒ–å—é™")
    
    if not missing and not tensorrt_issues and not ncnn_issues:
        print(f"   âœ… æœªå‘ç°é—®é¢˜")
    
    # æœ€ç»ˆç»“æœ
    if missing:
        print("\nâŒ ç¯å¢ƒæ£€æŸ¥æœªå®Œå…¨é€šè¿‡ - ç¼ºå°‘å¿…éœ€çš„Pythonä¾èµ–")
        return False
    else:
        print("\nâœ… æ ¸å¿ƒPythonä¾èµ–æ£€æŸ¥é€šè¿‡")
        if tensorrt_issues:
            print("âš ï¸  TensorRTåŠŸèƒ½å—é™ï¼ŒGPUåŠ é€Ÿæ€§èƒ½å¯èƒ½ä¸‹é™")
        if ncnn_issues:
            print("âš ï¸  NCNNåŠŸèƒ½å—é™ï¼ŒCPUç§»åŠ¨ç«¯ä¼˜åŒ–å¯èƒ½ä¸å¯ç”¨")
        if not tensorrt_issues and not ncnn_issues:
            print("ğŸ‰ æ‰€æœ‰åŠŸèƒ½ç»„ä»¶å®Œå…¨å¯ç”¨ï¼")
        return True

if __name__ == "__main__":
    success = check_dependencies()
    if not success:
        print("\nğŸ’¡ ä¿®å¤å»ºè®®:")
        print("1. å®‰è£…Pythonä¾èµ–: pip install -r requirements.txt")
        print("2. ä¸‹è½½å¹¶é…ç½®TensorRTåº“:")
        print("   export LD_LIBRARY_PATH=~/work/depend_config/tensorrt/TensorRT-8.6.1.6/lib:$LD_LIBRARY_PATH")
        print("3. ä¸‹è½½å¹¶é…ç½®NCNNå·¥å…·åŒ…:")
        print("   export PATH=~/work/depend_config/ncnn/ncnn-20231027-ubuntu-2004-shared/bin:$PATH")
        print("   export LD_LIBRARY_PATH=~/work/depend_config/ncnn/usr/lib/x86_64-linux-gnu:~/work/depend_config/ncnn/ncnn-20231027-ubuntu-2004-shared/lib:$LD_LIBRARY_PATH")
        print("4. ç¡®ä¿CUDA 12.x + å¯¹åº”cuDNNç‰ˆæœ¬")
        print("5. é‡æ–°è¿è¡Œæ£€æŸ¥: python 00_check_deps.py")
        exit(1)
    else:
        print("\nğŸš€ ç¯å¢ƒæ£€æŸ¥é€šè¿‡ï¼Œå¯ä»¥å¼€å§‹ä½¿ç”¨ï¼")
        print("ğŸ’¡ ä¸‹ä¸€æ­¥: python 01_infer_basic.py")