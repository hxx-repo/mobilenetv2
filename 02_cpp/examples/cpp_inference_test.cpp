#include "inference_backend.hpp"
#include <iostream>
#include <iomanip>
#include <numeric>
#include <cmath>
#include <fstream>
#include <algorithm>
#include <vector>
#include <string>

using namespace mobilenet_inference;

// åŠ è½½ImageNetæ ‡ç­¾æ–‡ä»¶
std::vector<std::string> load_labels(const std::string& labels_path) {
    std::vector<std::string> labels;
    std::ifstream file(labels_path);
    if (file.is_open()) {
        std::string line;
        while (std::getline(file, line)) {
            labels.push_back(line);
        }
        file.close();
    }
    return labels;
}

// è¾…åŠ©å‡½æ•°ï¼šè®¡ç®—ç»Ÿè®¡ä¿¡æ¯ - å®Œå…¨å¯¹é½Pythoné‡æ„ç‰ˆæœ¬è¾“å‡º  
void print_benchmark_stats(const BenchmarkResult& result, const std::vector<std::string>& labels = {}) {
    if (result.inference_times.empty()) {
        std::cout << "æ²¡æœ‰æœ‰æ•ˆçš„æ¨ç†æ—¶é—´æ•°æ®" << std::endl;
        return;
    }
    
    // è®¡ç®—ç»Ÿè®¡æ•°æ® - å¯¹é½Pythonçš„è®¡ç®—é€»è¾‘
    double avg_time = std::accumulate(result.inference_times.begin(), 
                                     result.inference_times.end(), 0.0) / result.inference_times.size();
    double min_time = *std::min_element(result.inference_times.begin(), result.inference_times.end());
    double max_time = *std::max_element(result.inference_times.begin(), result.inference_times.end());
    
    // è®¡ç®—æ ‡å‡†å·®
    double variance = 0.0;
    for (double time : result.inference_times) {
        variance += (time - avg_time) * (time - avg_time);
    }
    variance /= result.inference_times.size();
    double std_time = std::sqrt(variance);
    
    // å¯¹é½Pythoné‡æ„ç‰ˆæœ¬çš„æ€§èƒ½ç»Ÿè®¡è¾“å‡ºæ ¼å¼
    std::cout << "\nğŸ“Š æ€§èƒ½ç»Ÿè®¡:" << std::endl;
    std::cout << std::fixed << std::setprecision(4);
    std::cout << "   é¢„å¤„ç†è€—æ—¶: " << result.preprocess_time << "ç§’" << std::endl;
    std::cout << "   å¹³å‡æ¨ç†è€—æ—¶: " << avg_time << "ç§’ (" << (1.0 / avg_time) << " FPS)" << std::endl;
    std::cout << "   æœ€å¿«æ¨ç†è€—æ—¶: " << min_time << "ç§’ (" << (1.0 / min_time) << " FPS)" << std::endl;
    std::cout << "   æœ€æ…¢æ¨ç†è€—æ—¶: " << max_time << "ç§’ (" << (1.0 / max_time) << " FPS)" << std::endl;
    std::cout << "   æ ‡å‡†å·®: " << std_time << "ç§’" << std::endl;
    if (result.postprocess_time > 0.0) {
        std::cout << "   åå¤„ç†è€—æ—¶: " << result.postprocess_time << "ç§’" << std::endl;
    }
    
    // è¾“å‡ºTop-5é¢„æµ‹ç»“æœ
    if (!result.predictions.empty()) {
        std::cout << "\nTop-5 é¢„æµ‹ç»“æœ:" << std::endl;
        
        // æ‰¾å‡ºæœ€å¤§çš„5ä¸ªæ¦‚ç‡åŠå…¶ç´¢å¼•
        std::vector<std::pair<int, float>> indexed_probs;
        for (size_t i = 0; i < result.predictions.size(); ++i) {
            indexed_probs.emplace_back(static_cast<int>(i), result.predictions[i]);
        }
        
        std::partial_sort(indexed_probs.begin(), 
                         indexed_probs.begin() + std::min(5, static_cast<int>(indexed_probs.size())),
                         indexed_probs.end(),
                         [](const auto& a, const auto& b) { return a.second > b.second; });
        
        for (int i = 0; i < std::min(5, static_cast<int>(indexed_probs.size())); ++i) {
            int class_idx = indexed_probs[i].first;
            std::string class_name = "class_" + std::to_string(class_idx);
            std::string real_label = (labels.size() > static_cast<size_t>(class_idx)) ? 
                                     labels[class_idx] : ("unknown_" + std::to_string(class_idx));
            std::cout << "  " << (i + 1) << ". " << class_name << " (" << real_label << "): " 
                      << std::setprecision(6) << indexed_probs[i].second 
                      << " (" << std::setprecision(1) << (indexed_probs[i].second * 100) << "%)" << std::endl;
        }
    }
}

// è§£æåç«¯ç±»å‹
BackendFactory::BackendType parse_backend_type(const std::string& model_path) {
    if (model_path.find(".tflite") != std::string::npos) {
        return BackendFactory::BackendType::TFLITE;
    } else if (model_path.find(".onnx") != std::string::npos) {
        return BackendFactory::BackendType::ONNX_RUNTIME;
    } else if (model_path.find(".trt") != std::string::npos) {
        // æ ¹æ®æ–‡ä»¶åä¸­çš„ç²¾åº¦æ ‡è¯†ç¬¦åŒºåˆ†TensorRTç±»å‹
        if (model_path.find("_fp16") != std::string::npos) {
            return BackendFactory::BackendType::TENSORRT_FP16;
        } else if (model_path.find("_int8") != std::string::npos) {
            return BackendFactory::BackendType::TENSORRT_INT8;
        } else {
            return BackendFactory::BackendType::TENSORRT_FP32; // é»˜è®¤æˆ–fp32
        }
    } else if (model_path.find(".param") != std::string::npos) {
        // åŒºåˆ†NCNNçš„é‡åŒ–ç‰ˆæœ¬
        if (model_path.find("-int8") != std::string::npos) {
            return BackendFactory::BackendType::NCNN_INT8_QUANT;
        } else {
            return BackendFactory::BackendType::NCNN;
        }
    }
    
    // é»˜è®¤å°è¯•TFLite
    return BackendFactory::BackendType::TFLITE;
}

int main(int argc, char* argv[]) {
    // å‚æ•°æ£€æŸ¥ - æ”¯æŒå¤šåç«¯è‡ªåŠ¨è¯†åˆ«
    if (argc < 3 || argc > 4) {
        std::cout << "ç”¨æ³•: " << argv[0] << " <æ¨¡å‹æ–‡ä»¶è·¯å¾„> <å›¾åƒæ–‡ä»¶è·¯å¾„> [labelsæ–‡ä»¶è·¯å¾„]" << std::endl;
        std::cout << "æ”¯æŒçš„æ¨¡å‹æ ¼å¼:" << std::endl;
        std::cout << "  TFLite: *.tflite" << std::endl;
        std::cout << "  ONNX: *.onnx" << std::endl;
        std::cout << "  TensorRT: *.trt" << std::endl;
        std::cout << "  NCNN: *.param" << std::endl;
        std::cout << "ç¤ºä¾‹: " << argv[0] << " ../model/mobilenet_v2_1.0_224.tflite ../input/fish_224x224.jpeg ../model/labels.txt" << std::endl;
        return 1;
    }
    
    std::string model_path = argv[1];
    std::string image_path = argv[2];
    std::string labels_path = (argc == 4) ? argv[3] : "";
    
    // è‡ªåŠ¨æ£€æµ‹åç«¯ç±»å‹
    BackendFactory::BackendType backend_type = parse_backend_type(model_path);
    std::string backend_name = BackendFactory::BackendTypeToString(backend_type);
    
    std::cout << "MobileNetV2 C++ å¤šåç«¯æ¨ç†æµ‹è¯• (å¯¹é½Pythonç‰ˆæœ¬)" << std::endl;
    std::cout << "===============================================" << std::endl;
    std::cout << "åç«¯ç±»å‹: " << backend_name << std::endl;
    std::cout << "æ¨¡å‹æ–‡ä»¶: " << model_path << std::endl;
    std::cout << "å›¾åƒæ–‡ä»¶: " << image_path << std::endl;
    
    // æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if (!std::ifstream(model_path).good()) {
        std::cerr << "âŒ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: " << model_path << std::endl;
        return 1;
    }
    
    if (!std::ifstream(image_path).good()) {
        std::cerr << "âŒ å›¾åƒæ–‡ä»¶ä¸å­˜åœ¨: " << image_path << std::endl;
        return 1;
    }
    
    try {
        // å®Œå…¨å¯¹é½Pythonè°ƒç”¨æ–¹å¼
        // Python: backend = TFLiteBackend(model_path)
        // Python: avg_time, predictions = benchmark_model(backend, args.image, args.runs)
        std::cout << "\nåˆ›å»º" << backend_name << "åç«¯..." << std::endl;
        auto backend = BackendFactory::CreateBackend(backend_type, model_path);
        
        if (!backend) {
            std::cerr << "âŒ åç«¯åˆ›å»ºå¤±è´¥" << std::endl;
            return 1;
        }
        
        // åŠ è½½labelsæ–‡ä»¶
        std::vector<std::string> labels;
        if (!labels_path.empty()) {
            labels = load_labels(labels_path);
            if (labels.empty()) {
                std::cout << "âš ï¸  æ— æ³•åŠ è½½labelsæ–‡ä»¶: " << labels_path << std::endl;
            } else {
                std::cout << "âœ… åŠ è½½labelsæ–‡ä»¶: " << labels_path << std::endl;
            }
        }
        
        std::cout << "æ‰§è¡Œæ€§èƒ½æµ‹è¯• - å®Œå…¨å¯¹é½Pythonè°ƒç”¨æ–¹å¼..." << std::endl;
        BenchmarkResult benchmark_result = benchmark_model(*backend, image_path, 20);
        
        // è¾“å‡ºæ€§èƒ½æŠ¥å‘Š
        print_benchmark_stats(benchmark_result, labels);
        
        std::cout << "\nâœ… æ‰€æœ‰æµ‹è¯•å®Œæˆï¼ä¸Pythonç‰ˆæœ¬è¡Œä¸ºå®Œå…¨ä¸€è‡´ã€‚" << std::endl;
        
    } catch (const std::exception& e) {
        std::cerr << "âŒ æ‰§è¡Œè¿‡ç¨‹ä¸­å‡ºç°å¼‚å¸¸: " << e.what() << std::endl;
        return 1;
    }
    
    return 0;
}